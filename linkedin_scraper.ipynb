{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using session ID to authenticate\n"
     ]
    }
   ],
   "source": [
    "\\import os\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "LI_AT = os.getenv(\"LI_AT\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--headless\")  # Add this line to run in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def use_session_cookie(driver):\n",
    "    \"\"\"Use a session ID to log in to LinkedIn.\"\"\"\n",
    "    logging.info(\"Using session ID to authenticate\")\n",
    "    driver.get(\"https://www.linkedin.com\")  # Open LinkedIn home page\n",
    "    driver.add_cookie({\n",
    "        'name': 'li_at',\n",
    "        'value': LI_AT,\n",
    "        'domain': '.linkedin.com'\n",
    "    })\n",
    "    driver.refresh()\n",
    "\n",
    "def scroll_down(driver):\n",
    "    \"\"\"Scroll down to load all dynamic content.\"\"\"\n",
    "    logging.info(\"Scrolling down the page...\")\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "        time.sleep(1)  # Reduced sleep time\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "def extract_profile_data(driver, url):\n",
    "    logging.info(f\"Scraping profile data from {url}\")\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "    scroll_down(driver)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "    profile_data = {}\n",
    "\n",
    "    # Basic Profile Information\n",
    "    name = soup.find('h1', {'class': 'text-heading-xlarge'})\n",
    "    if name:\n",
    "        profile_data['name'] = name.get_text(strip=True)\n",
    "\n",
    "    # Headline\n",
    "    headline = soup.find('div', {'class': 'text-body-medium break-words'})\n",
    "    if headline:\n",
    "        profile_data['headline'] = headline.get_text(strip=True)\n",
    "    \n",
    "    # About Section\n",
    "    about_section = soup.find('div', {'class': 'display-flex ph5 pv3'})\n",
    "    if about_section:\n",
    "        profile_data['about'] = about_section.get_text(strip=True)\n",
    "    \n",
    "    # Get all sections once\n",
    "    sections = soup.find_all('section', {'class': 'artdeco-card pv-profile-card break-words mt2'})\n",
    "    \n",
    "    # Education Section\n",
    "    for sec in sections:\n",
    "        if sec.find('div', {'id': 'education'}):\n",
    "            profile_data['education'] = sec.get_text(strip=True)\n",
    "            break\n",
    "    \n",
    "    # Experience Section\n",
    "    for sec in sections:\n",
    "        if sec.find('div', {'id': 'experience'}):\n",
    "            experience_items = sec.find_all('li')\n",
    "            profile_data['experience'] = list(dict.fromkeys([item.get_text(strip=True) for item in experience_items]))\n",
    "            break\n",
    "    \n",
    "    # Organizations Section\n",
    "    for sec in sections:\n",
    "        if sec.find('div', {'id': 'organizations'}):\n",
    "            organization_items = sec.find_all('li', {'class': 'artdeco-list__item'})\n",
    "            profile_data['organizations'] = [{\n",
    "                'name': item.find('span', {'aria-hidden': 'true'}).get_text(strip=True) if item.find('span', {'aria-hidden': 'true'}) else None,\n",
    "                'role': item.find('span', {'class': 't-14 t-normal'}).get_text(strip=True) if item.find('span', {'class': 't-14 t-normal'}) else None\n",
    "            } for item in organization_items]\n",
    "            break\n",
    "    \n",
    "    # Interests Section Categorization\n",
    "    interests_section = None\n",
    "    for sec in sections:\n",
    "        if sec.find('div', {'id': 'interests'}):\n",
    "            interests_section = sec\n",
    "            break\n",
    "    \n",
    "    profile_data['interests'] = {\n",
    "        'Top Voices': [],\n",
    "        'Companies': [],\n",
    "        'Groups': [],\n",
    "        'Newsletters': []\n",
    "    }\n",
    "    \n",
    "    if interests_section:\n",
    "        interest_items = interests_section.find_all('li')\n",
    "        for item in interest_items:\n",
    "            text = item.get_text(strip=True)\n",
    "            if any(kw in text.lower() for kw in [\"chair\", \"head\", \"keynote\", \"speaker\", \"researcher\", \"coach\"]):\n",
    "                profile_data['interests']['Top Voices'].append(text.split(\"\\n\")[0])\n",
    "            elif \"followers\" in text.lower():\n",
    "                profile_data['interests']['Companies'].append(text.split(\"followers\")[0].strip())\n",
    "            elif \"members\" in text.lower():\n",
    "                profile_data['interests']['Groups'].append(text.split(\"members\")[0].strip())\n",
    "            elif \"published\" in text.lower():\n",
    "                profile_data['interests']['Newsletters'].append(text.split(\"published\")[0].strip())\n",
    "    \n",
    "    return profile_data\n",
    "\n",
    "def scrape_website(url):\n",
    "    driver = get_driver()\n",
    "    try:\n",
    "        use_session_cookie(driver)\n",
    "        profile_data = extract_profile_data(driver, url)\n",
    "        print(json.dumps(profile_data, indent=4))  # Output as JSON\n",
    "        return profile_data\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "def scrape_multiple_profiles(urls):\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        results = list(executor.map(scrape_website, urls))\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    linkedin_urls = [\n",
    "        \"https://www.linkedin.com/in/rajender-sharma-bb2a7718/\",\n",
    "        # Add more LinkedIn profile URLs here\n",
    "    ]\n",
    "    scrape_multiple_profiles(linkedin_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
